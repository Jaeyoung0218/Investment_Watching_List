import pandas as pd
import requests
from bs4 import BeautifulSoup
from matplotlib import pyplot as plt

if response.status_code == 200:
    html = response.text
    bs = BeautifulSoup(html, 'lxml')
    pgrr = bs.find('td', class_='pgRR')
    
code = '389500'      # 에스비비테크 종목 코드
url = f'https://finance.naver.com/item/sise_day.naver?code={code}'
headers = {'User-Agent': 'Mozilla/5.0'}
response = requests.get(url, headers=headers)

pgrr = html.find('td', class_='pgRR')
s = prgg.a['href'].split('=')
last_page = s[-1]                      #마지막 페이수의 숫자 출력

for  page in range(1, int(last_page)+1):
     response = requests.get(f'{url}&page={page}', headers=headers)
     df = pd.concat([df, pd.read_html(req.text, encoding = 'euc-kr')[0]], ignore_index = True)

df.dropna(inplace = True)              #데이터가 없는 행 삭제
df.reset_index(drop = True, inplace = Ture) #인덱스 재배열


df.to_excel("Watching_list.xlsx", index = False)


--------------------------------------------------------------------

bs = BeautifulSoup(html, 'lxml')
pgrr = bs.find('td', class_='pgRR')


if response.status_code == 200:
    html = response.text
    bs = BeautifulSoup(html, 'lxml')
    pgrr = bs.find('td', class_='pgRR')

    if pgrr:
        s = str(pgrr.a['href']).split('=')
        last_page = s[-1]

        df = pd.DataFrame()
        sise_url = 'https://finance.naver.com/item/sise_day.naver?code=389500'

        for page in range(1, int(last_page) + 1):
            url = '{}&page={}'.format(sise_url, page)
            response = requests.get(url, headers=headers)

            if response.status_code == 200:
                html = response.text
                df = df.append(pd.read_html(html, header=0)[0])
            else:
                print(f"Failed to retrieve data for page {page}")
        
    else:
        print("The 'pgRR' element was not found.")

else:
    print("Failed to retrieve the initial page.")
    
    
